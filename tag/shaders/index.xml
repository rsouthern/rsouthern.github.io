<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>shaders | Richard's Blog</title><link>https://rsouthern.github.io/tag/shaders/</link><atom:link href="https://rsouthern.github.io/tag/shaders/index.xml" rel="self" type="application/rss+xml"/><description>shaders</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-uk</language><lastBuildDate>Tue, 01 May 2018 00:00:00 +0000</lastBuildDate><image><url>https://rsouthern.github.io/images/icon_hu0365f2187e15210a9118469a64220edc_142871_512x512_fill_lanczos_center_2.png</url><title>shaders</title><link>https://rsouthern.github.io/tag/shaders/</link></image><item><title>Realtime Silhouette Rendering with Consistent Geometric Fins</title><link>https://rsouthern.github.io/post/fins/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://rsouthern.github.io/post/fins/</guid><description>&lt;h3 id="background">Background&lt;/h3>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Cel_shading">Cel shading&lt;/a> is a common shading technique designed to make 3D geometry look like it was hand painted in a traditional way. While it is fairly trivial to darken vertices on the silhouette, to truly emulate the effect of a hand drawn outline, the ink outline must extend &lt;em>outside&lt;/em> the silhouette of the object at a constant thickness for it to appear plausible. Games like &lt;a href="https://en.wikipedia.org/wiki/Borderlands_(video_game)">Borderlands&lt;/a> make liberal use of outline geometry to enhance the non-photorealistic style of the game.&lt;/p>
&lt;p>My starting point was the &lt;a href="http://prideout.net/blog/?p=54">blog post&lt;/a> by Philip Rideout in which gaps between fins are blended using a blurring pass, which seemed wasteful, and may prohibit procedural outline effects like glowing or outline particles.&lt;/p>
&lt;p>I started from scratch, but what I ended up with is a method similar to &lt;a href="http://cgstarad.com/Docs/GSContours.pdf">Single Pass GPU Stylized Edges&lt;/a> by Hermosilla and Vazquez, although implemented on the geometry shader, and also requiring about half the additional geometry. I would also argue that the method I&amp;rsquo;ve produced here is considerably simpler than any previous method.&lt;/p>
&lt;h4 id="what-is-the-silhouette">What is the Silhouette?&lt;/h4>
&lt;p>This is probably a good place to start. Assume for the moment that we have some nice continuous object (not a triangle mesh) like a perfect sphere. The silhouette is effectively a connected curve around the object where the surface of the object is exactly orthogonal to the direction of the viewer. Consider the horizon - the silhouette is the exact point at which the ground meets the sky.&lt;/p>
&lt;p>Based on this we could formulate a simple definition of the silhouette as the set of all points \(x\) for which \(\mathbf{v}_x \cdot \mathbf{n}_x = 0 \), where \(\mathbf{v}_x\) is the view vector from the eye to \(x\) and \(\mathbf{n}_x\) is the normal at the point \(x\).&lt;/p>
&lt;h3 id="method-overview">Method Overview&lt;/h3>
&lt;h4 id="determining-the-silhouette-of-a-triangle-mesh">Determining the silhouette of a triangle mesh&lt;/h4>
&lt;p>Now lets consider this on a triangle mesh. Any silhouette is only going exist between points on two edges of a subset of triangles on the mesh. We will assume that our triangle mesh is sufficiently dense so we can approximate the silhouette across the triangle face with a straight line (it would be possible to generate smoother curves using a Bezier spline or equivalent). The comparison of the discrete and the continuous silhouette case is demonstrated in the figure below:&lt;/p>
&lt;center>&lt;img src="continuous_silhouette.svg"/>&lt;/center>
&lt;p>Remember that a triangle mesh is typically an approximation of some smoother surface representation, and should in most cases have vertex normals defined which effectively allow us to generate smooth shading across each face, giving the illusion of a continuous surface representation. We can use this knowledge to determine which faces are on the silhouette.&lt;/p>
&lt;p>Consider an edge with vertices at \(p_{0,1} \) with vertex normals \( \mathbf{n}_{0,1} \) respectively. If \(\mathbf{v}_0 \cdot \mathbf{n}_0 &amp;lt; 0 \) and \(\mathbf{v}_1 \cdot \mathbf{n}_1 &amp;gt; 0 \) (or visa versa), then somewhere along this edge there is an \(x\) for which \(\mathbf{v}_x \cdot \mathbf{n}_x = 0 \).&lt;/p>
&lt;p>A wary reader will note that \(\mathbf{v}_0 \neq \mathbf{v}_1\) which might cause problems, but as we will see, all view vectors \(\mathbf{v}_x\) will be the same \(\forall x\).&lt;/p>
&lt;h4 id="interpolation">Interpolation&lt;/h4>
&lt;p>So we need to find the point \(x\) across the edge for which \(\mathbf{v}_x \cdot \mathbf{n}_x = 0 \). We&amp;rsquo;re going to make a couple of assumptions to simplify things. The first assumption is that we&amp;rsquo;re going to use simple linear interpolation for performance reasons. Accuracy will be affected, but we&amp;rsquo;re going to assume that the input mesh is dense and any accuracy issues will not be noticeable.&lt;/p>
&lt;p>Linear interpolation would imply that we&amp;rsquo;re looking for some \(t\) for which \((1-t)\mathbf{v}_0 \cdot \mathbf{n}_0 + t \mathbf{v}_1 \cdot \mathbf{n}_1 = \mathbf{v}_x \cdot \mathbf{n}_x = 0 \), e.g. the interpolation parameter for which the the normal is zero.&lt;/p>
&lt;p>The second assumption we&amp;rsquo;ll be creating the geometry of the fin on the &lt;a href="https://www.khronos.org/opengl/wiki/Geometry_Shader">geometry shader&lt;/a>, which means that by &lt;a href="https://www.khronos.org/opengl/wiki/Vertex_Shader">convention&lt;/a> we can rely on the fact that the geometry has already been projected, which means it already lives within a &lt;a href="https://cglearn.codelight.eu/pub/computer-graphics/frames-of-reference-and-projection">canonical viewing volume&lt;/a>. We can now reliably state that \(\mathbf{v}_0 = \mathbf{v}_1 = [0,0,-1]^T\), i.e. the view vector for all vertices is just from the origin looking in the \(-z\) direction by the &lt;a href="http://www.songho.ca/opengl/gl_transform.html">OpenGL camera convention&lt;/a>.&lt;/p>
&lt;p>So this means that we can simplify the formulation significantly to just \( (1-t) \mathbf{n}_{(0,z)} + t\mathbf{n}_{(1,z)} = 0 \), which yields \( t = -\mathbf{n}_{(0,z)} / (\mathbf{n}_{(1,z)}-\mathbf{n}_{(0,z)}) \). Built into this formula is also the implicit test: \( 0 \leq t \leq 1 \implies \) the edge crosses the silhouette.&lt;/p>
&lt;p>Below is this trivial function as implemented in the geometry shader:&lt;/p>
&lt;pre>&lt;code class="language-cpp">/** This is where most of the magic happens - it determines the interpolation value
* based on the z values of the two normals in order to detemrine a normal pointing
* out orthogonal to the view direction.
* \param n0,n1 The two input normals
* \return The output interpolation value (between 0 and 1 if edge is on the silhouette)
*/
float isSilhouette(in vec3 n0, in vec3 n1) {
// Trivial case: the normals are the same, so we'll just pick a point in the middle
if (n1.z == n0.z) {
return 0.5;
} else {
// Use our formula to determine the interpolation value and return a boolean based
// on whether the interpolant is within the two input vectors
return - n0.z / (n1.z - n0.z);
}
}
&lt;/code>&lt;/pre>
&lt;h4 id="putting-it-together">Putting it together&lt;/h4>
&lt;p>The geometry shader to generate fins accepts a triangle as input and spawns a triangle strip of 4 vertices as output. Each triangle is going to be processed, and we can expect neighbouring triangles on the silhouette to be consistent - see the image below for an example (I appreciate that it&amp;rsquo;s not great):&lt;/p>
&lt;center>&lt;img src="discrete_silhouette.svg"/>&lt;/center>
&lt;p>The geometry shader iterates over all edges of the triangle and determines the value of \(t\) to see if it lies on the silhouette. If it does, a fin vertex and normal is determined using a straight linear interpolation (via the built-in mix function):&lt;/p>
&lt;pre>&lt;code class="language-cpp"> // Iterate over all the edges in our triangle
int j;
for (int i = 0; i &amp;lt; 3; ++i) {
j = (i+1)%3;
t[cnt] = isSilhouette(normal[i], normal[j]);
if ((t[cnt] &amp;gt;= 0.0) &amp;amp;&amp;amp; (t[cnt] &amp;lt;= 1.0)) {
finVerts[cnt] = mix(pos[i], pos[j], t[cnt]);
finNorms[cnt] = normalize(mix(normal[i], normal[j], t[cnt]));
++cnt;
}
}
&lt;/code>&lt;/pre>
&lt;p>I did also experiment with higher order mixing methods, but these showed no discernable improvement and just added significantly to the computation cost and complexity so these approaches were scrapped.&lt;/p>
&lt;p>Now if the variable cnt is exactly 2 then we know that this triangle cuts the silhouette and we need to generate a triangle strip fin:&lt;/p>
&lt;pre>&lt;code class="language-cpp"> // If count is less than 2 don't do anything as there isn't a fin
if (cnt &amp;gt;= 2) {
// Create our triangle strip from the two input vertices and normals
finColour = vec4(0,0,0,1); // You might want to visualise something with the color
gl_Position = vec4(finVerts[0],1.0);
EmitVertex();
gl_Position = vec4(finVerts[1],1.0);
EmitVertex();
gl_Position = vec4(finVerts[0] + finScale * finNorms[0],1.0);
EmitVertex();
gl_Position = vec4(finVerts[1] + finScale * finNorms[1],1.0);
EmitVertex();
EndPrimitive();
}
&lt;/code>&lt;/pre>
&lt;p>Note that the rendering of the fin is an additional render pass performed after you&amp;rsquo;ve rendered the main geometry, as the geometry shader will effectively &amp;ldquo;eat&amp;rdquo; the original geometry.&lt;/p>
&lt;h3 id="results">Results&lt;/h3>
&lt;p>Here are a couple of Buddha&amp;rsquo;s of various levels of thickness:&lt;/p>
&lt;table width=100%>
&lt;tr>
&lt;td>&lt;img src="buddha1.png" width=100% />&lt;/td>
&lt;td>&lt;img src="buddha2.png" width=100%/>&lt;/td>
&lt;td>&lt;img src="buddha3.png" width=100%/>&lt;/td>
&lt;/tr>
&lt;/table>
&lt;p>The results are close to perfect: the fins are consistent about both internal and external silhouettes. There are still a couple of problems which need resolving:&lt;/p>
&lt;ul>
&lt;li>The normals are not transformed correctly after projection. This is because the normals are needed in the world coordinates for the lighting calculations. You can see the error in that the line is not the same width everywhere on the silhouette. Unfortunately I&amp;rsquo;ve not yet figured out the correct method to transform the normals to be correct according to the canonical viewing volume - feel free to contact me if you have a solution to this.&lt;/li>
&lt;li>The lines don&amp;rsquo;t taper when nearing the edge of an internal silhouette (leading to &amp;ldquo;sharpy edges&amp;rdquo;). This could be fixed by tiling a round texture map on the silhouette so the borders become rounded.&lt;/li>
&lt;li>I have not explored all the fun effects that fins can do, like glow or illustrative visualisation: this is up to you!&lt;/li>
&lt;/ul>
&lt;h3 id="downloads">Downloads&lt;/h3>
&lt;p>The source code is hosted on &lt;a href="https://github.com/rsouthern/Examples">GitHub&lt;/a>. Clone it from the repository using the following command from your console:&lt;/p>
&lt;pre>&lt;code class="language-shell">git clone https://github.com/rsouthern/Examples
&lt;/code>&lt;/pre>
&lt;p>This example is under rendering/fins.&lt;/p></description></item><item><title>A Templated Implementation of Noise Texture</title><link>https://rsouthern.github.io/post/noisetexture/</link><pubDate>Thu, 30 Jun 2016 00:00:00 +0000</pubDate><guid>https://rsouthern.github.io/post/noisetexture/</guid><description>&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>The icon for this page was from my attempt to recreate a realtime shader for a varnished woodgrain effect. This approach requires the &lt;a href="http://libnoise.sourceforge.net/examples/textures/">combination of multiple layers&lt;/a> of &lt;a href="http://mrl.nyu.edu/~perlin/">Perlin&lt;/a> &lt;a href="https://en.wikipedia.org/wiki/Perlin_noise">noise&lt;/a>, which is probably infeasible to &lt;a href="https://github.com/ashima/webgl-noise/wiki">generate on the fly within the fragment shader&lt;/a> (although I&amp;rsquo;d love to be proven wrong). The generation of the wood grain shader will be saved for another post - in this one I&amp;rsquo;d like to discuss how I implemented a generic C++ template for the initialisation of the &amp;ldquo;general&amp;rdquo; dimensional noise texture on OpenGL.&lt;/p>
&lt;h3 id="the-high-level-interface">The High Level Interface&lt;/h3>
&lt;p>The central idea behind this class was to provide the following generalisations:&lt;/p>
&lt;ol>
&lt;li>&lt;em>General Dimensional Textures&lt;/em> - noise textures are typically either 2D or 3D (so you can &amp;ldquo;slice through&amp;rdquo; your material and expect a consistent pattern).&lt;/li>
&lt;li>&lt;em>Generic Generator Functions&lt;/em> - the function that actually generates the noise must be completely generic.&lt;/li>
&lt;/ol>
&lt;p>For (1) above, this is realised by using a simple template parameter DIM:&lt;/p>
&lt;pre>&lt;code class="language-cpp">template &amp;lt;size_t DIM&amp;gt;
class NoiseTexture
&lt;/code>&lt;/pre>
&lt;p>So my interface to creating a 3D texture is something like:&lt;/p>
&lt;pre>&lt;code class="language-cpp"> MyNoiseTexture&amp;lt;3&amp;gt; m_noise;
&lt;/code>&lt;/pre>
&lt;p>For (2), there were several ways to approach this. I could, for example, have passed a generator function / functor class as a template parameter. This would have required me to create different classes for each type of generation. However there are a couple of reasons why I used inheritance instead of this approach (which could be called the &lt;a href="http://www.bogotobogo.com/DesignPatterns/strategy.php">strategy pattern&lt;/a>):&lt;/p>
&lt;ul>
&lt;li>A function cannot store state, which is need for many noise generators, for example &lt;a href="http://www.boost.org/doc/libs/1_61_0/doc/html/boost_random.html">boost&lt;/a> or &lt;a href="http://libnoise.sourceforge.net/index.html">libnoise&lt;/a>,&lt;/li>
&lt;li>A functor can store state, but will have the same level of class management and complexity as using inheritance, but more importantly&lt;/li>
&lt;li>I may want to override other parts of the class to support parallel noise generation.&lt;/li>
&lt;/ul>
&lt;p>The interface noisetexture.h provides is to inherit from the base class and override the protected function&lt;/p>
&lt;pre>&lt;code class="language-cpp"> /// A generator function to make the process of building noise easy
virtual inline GLfloat generator_func(const CoordinateArrayf &amp;amp;) = 0;
&lt;/code>&lt;/pre>
&lt;p>This function simply accepts a coordinate in DIM space and returns a floating point value. Note that the NoiseTexture makes use of std::array as it should - this makes sure that this is managed memory rather than pointers. Two different arrays are defined:&lt;/p>
&lt;pre>&lt;code class="language-cpp"> /// A static (i.e. not dynamic allocated) vector
typedef std::array&amp;lt;size_t,DIM&amp;gt; CoordinateArray;
typedef std::array&amp;lt;float, DIM&amp;gt; CoordinateArrayf;
&lt;/code>&lt;/pre>
&lt;p>One is for indices and the other for positions. This will be used in the recursive generation of the data block.&lt;/p>
&lt;h3 id="generating-the-data">Generating the data&lt;/h3>
&lt;p>Ultimately the initialisation of the OpenGL texture consists of copying a lump of data from the CPU memory to the GPU memory using a call to glTexImage. The following section of code creates the memory, fills it with data and copies it to the GPU:&lt;/p>
&lt;pre>&lt;code class="language-cpp"> // Allocate a slab of data for the stuffing
GLfloat *data = (GLfloat*) malloc(sizeof(GLfloat) * pow(m_res,DIM) * 3);
// Use the recursive function to generate the data recursively
CoordinateArray coord;
generate_recurse(DIM, coord, data);
// Copy our data over to the GPU
copyTextureDataToGPU(data);
// Delete our data - it's been copied onto the GPU right?
free(data);
&lt;/code>&lt;/pre>
&lt;p>Unpicking the memory allocation from left to right:&lt;/p>
&lt;ul>
&lt;li>sizeof(GLfloat) - the size of an individual value (single precision)&lt;/li>
&lt;li>pow(m_res,DIM) - the size of the block of data is squared/cubed as you would expect&lt;/li>
&lt;li>3 - we need RGB values to copy to the GPU&lt;/li>
&lt;/ul>
&lt;p>Generate_recurse is defined as follows:&lt;/p>
&lt;pre>&lt;code class="language-cpp"> /// Recursively generate the data
virtual void generate_recurse(const size_t &amp;amp;/*dim*/, const CoordinateArray &amp;amp;/*coord*/, GLfloat */*data*/);
&lt;/code>&lt;/pre>
&lt;p>It will recursively evaluate the generator function on each of the different positions in the block of memory and write it to the appropriate index:&lt;/p>
&lt;pre>&lt;code class="language-cpp">template &amp;lt;size_t DIM&amp;gt;
void NoiseTexture&amp;lt;DIM&amp;gt;::generate_recurse(const size_t &amp;amp;d,
const CoordinateArray&amp;amp; coord,
GLfloat *data) {
size_t dim_length = 1, data_pos = 0, i;
CoordinateArrayf coordf, tmp;
CoordinateArray ncoord;
switch(d) {
case 0:
// At the end of the recursion chain we can evaluate the noise function
for (i=0; i&amp;lt;DIM; ++i) {
data_pos += coord[i] * dim_length;
dim_length *= m_res;
coordf[i] = m_inv_resf * float(coord[i]);
}
data_pos *= 3;
// Fill up the data with data defined by the generator_func()
for (i=0; i&amp;lt;3; ++i) {
tmp = coordf; coordf[i] += 1.0f;
data[data_pos + i] = generator_func(coordf);
}
break;
default:
// For the rest of the dimensions we recursively call all the remaining coordinates
ncoord = coord;
for (i=0; i&amp;lt;m_res; ++i) {
ncoord[d-1] = i;
generate_recurse(d-1, ncoord, data);
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Note that I have arbitrarily added 1.0f for each of the R, G, B channels to give a bit of a richer data set to play with.&lt;/p>
&lt;h3 id="opengl-integration">OpenGL integration&lt;/h3>
&lt;p>There are a number of standard functions which make this class usable in a GL context. For example, the function to find the texture:&lt;/p>
&lt;pre>&lt;code class="language-cpp">template &amp;lt;size_t DIM&amp;gt;
void NoiseTexture&amp;lt;DIM&amp;gt;::bind() const {
if (m_isInit) {
glBindTexture(m_target, m_texID);
CheckError(&amp;quot;NoiseTexture&amp;lt;DIM&amp;gt;::bind() - glBindTexture()&amp;quot;);
}
}
&lt;/code>&lt;/pre>
&lt;p>Note the variable m_target, which is actually a constant, defined using this from within the class declaration:&lt;/p>
&lt;pre>&lt;code class="language-cpp"> constexpr GLuint target() const {
switch(DIM) {
case 1:
return GL_TEXTURE_1D;
case 2:
return GL_TEXTURE_2D;
case 3:
return GL_TEXTURE_3D;
}
return 0;
}
const GLuint m_target = target();
&lt;/code>&lt;/pre>
&lt;p>Take a moment to digest this: the function target is actually being executed at &lt;em>compile time&lt;/em>, and this is in fact an example of &lt;a href="https://en.wikipedia.org/wiki/Template_metaprogramming">template metaprogramming&lt;/a> (albeit, a rather simple one). The keyword constexpr allows this function to be executed in setting a constant at compile time. The use of the switch statement (and using multiple return statements in a function) is only allowable in C++14 or better (a simple if-else structure would remove this dependency).&lt;/p>
&lt;p>The function which copies the data to the GPU is pretty straightforward:&lt;/p>
&lt;pre>&lt;code class="language-cpp">template &amp;lt;size_t DIM&amp;gt;
void NoiseTexture&amp;lt;DIM&amp;gt;::copyTextureDataToGPU(GLfloat *data) {
// Transfer this data to our texture
glGenTextures(1, &amp;amp;m_texID);
glBindTexture(m_target, m_texID);
// Repeat the texture for coordinates &amp;lt;0 or &amp;gt;1
...
// Use blending when texels are bigger or smaller than pixels
...
// Upload the texture data to the GPU
switch(DIM) {
case 1:
glTexImage1D(m_target, // Target
0, // Level
GL_RGB, // Internal Format
m_res, // width
0, // border
GL_RGB, // format
GL_FLOAT, // type
data);
break;
case 2:
...
case 3:
...
}
}
&lt;/code>&lt;/pre>
&lt;p>Note that template specialisms could have been used here for the different TexImage calls, but due to the duplication of the texture parameters I decided against it.&lt;/p>
&lt;h3 id="deriving-your-own-noise-texture-class">Deriving your own Noise Texture class&lt;/h3>
&lt;p>The simplest example of a derived noise texture class is one which just sets the values in the data block to 1. This is demonstrated in testnoisetexture.h:&lt;/p>
&lt;pre>&lt;code class="language-cpp">template&amp;lt;size_t DIM&amp;gt;
class TestNoiseTexture : public NoiseTexture&amp;lt;DIM&amp;gt; {
public:
/// Constructor
explicit TestNoiseTexture(float /*lower*/ = 0.0f,
float /*upper*/ = 1.0f,
size_t /*resolution*/ = 64);
/// Dtor
~TestNoiseTexture() {}
protected:
/// Specialisation of this class to generate pure white noise
inline GLfloat generator_func(const typename NoiseTexture&amp;lt;DIM&amp;gt;::CoordinateArrayf &amp;amp;);
};
template&amp;lt;size_t DIM&amp;gt;
TestNoiseTexture&amp;lt;DIM&amp;gt;::TestNoiseTexture(float _lower,
float _upper,
size_t _resolution)
: NoiseTexture&amp;lt;DIM&amp;gt;(_lower,_upper,_resolution) {}
template&amp;lt;size_t DIM&amp;gt;
inline GLfloat TestNoiseTexture&amp;lt;DIM&amp;gt;::generator_func(const typename NoiseTexture&amp;lt;DIM&amp;gt;::CoordinateArrayf &amp;amp;coord) {
return 1.0f;
}
&lt;/code>&lt;/pre>
&lt;p>As you see above, all you need to do here is override the virtual generator_func with your own favourite noise generator. See the whitenoisetexture.h example for something a little more interesting. I&amp;rsquo;ll be looking to write a post about how this method was used to create the wood shader soon.&lt;/p>
&lt;h3 id="downloads">Downloads&lt;/h3>
&lt;p>Download the source files for these here:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="noisetexture.h">noisetexture.h&lt;/a>&lt;/li>
&lt;li>&lt;a href="testnoisetexture.h">testnoisetexture.h&lt;/a>&lt;/li>
&lt;li>&lt;a href="whitenoisetexture.h">whitenoisetexture.h&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>